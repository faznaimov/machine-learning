{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:hellyeah] *",
      "language": "python",
      "name": "conda-env-hellyeah-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "fraud-detection.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xoay64D9uAYV",
        "colab_type": "text"
      },
      "source": [
        "# Credit Card Fraud Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YHIAHXbuAYX",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6iUs4u3uAYY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "8cf433d3-02b9-4902-d3b1-5222e8945f70"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "# for tensorflow version 2.0.0 and higher run the code below\n",
        "# import tensorflow.compat.v1 as tf\n",
        "# tf.disable_v2_behavior()\n",
        "import sklearn\n",
        "import time\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otmRIISTuAYb",
        "colab_type": "text"
      },
      "source": [
        "## Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x58uYdBYuAYc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "923586bc-2cbd-419d-d900-5302574d6192"
      },
      "source": [
        "# Import and store dataset\n",
        "credit_card_data = pd.read_csv('/tmp/creditcard.csv')\n",
        "credit_card_data.tail()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>284802</th>\n",
              "      <td>172786.0</td>\n",
              "      <td>-11.881118</td>\n",
              "      <td>10.071785</td>\n",
              "      <td>-9.834783</td>\n",
              "      <td>-2.066656</td>\n",
              "      <td>-5.364473</td>\n",
              "      <td>-2.606837</td>\n",
              "      <td>-4.918215</td>\n",
              "      <td>7.305334</td>\n",
              "      <td>1.914428</td>\n",
              "      <td>4.356170</td>\n",
              "      <td>-1.593105</td>\n",
              "      <td>2.711941</td>\n",
              "      <td>-0.689256</td>\n",
              "      <td>4.626942</td>\n",
              "      <td>-0.924459</td>\n",
              "      <td>1.107641</td>\n",
              "      <td>1.991691</td>\n",
              "      <td>0.510632</td>\n",
              "      <td>-0.682920</td>\n",
              "      <td>1.475829</td>\n",
              "      <td>0.213454</td>\n",
              "      <td>0.111864</td>\n",
              "      <td>1.014480</td>\n",
              "      <td>-0.509348</td>\n",
              "      <td>1.436807</td>\n",
              "      <td>0.250034</td>\n",
              "      <td>0.943651</td>\n",
              "      <td>0.823731</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284803</th>\n",
              "      <td>172787.0</td>\n",
              "      <td>-0.732789</td>\n",
              "      <td>-0.055080</td>\n",
              "      <td>2.035030</td>\n",
              "      <td>-0.738589</td>\n",
              "      <td>0.868229</td>\n",
              "      <td>1.058415</td>\n",
              "      <td>0.024330</td>\n",
              "      <td>0.294869</td>\n",
              "      <td>0.584800</td>\n",
              "      <td>-0.975926</td>\n",
              "      <td>-0.150189</td>\n",
              "      <td>0.915802</td>\n",
              "      <td>1.214756</td>\n",
              "      <td>-0.675143</td>\n",
              "      <td>1.164931</td>\n",
              "      <td>-0.711757</td>\n",
              "      <td>-0.025693</td>\n",
              "      <td>-1.221179</td>\n",
              "      <td>-1.545556</td>\n",
              "      <td>0.059616</td>\n",
              "      <td>0.214205</td>\n",
              "      <td>0.924384</td>\n",
              "      <td>0.012463</td>\n",
              "      <td>-1.016226</td>\n",
              "      <td>-0.606624</td>\n",
              "      <td>-0.395255</td>\n",
              "      <td>0.068472</td>\n",
              "      <td>-0.053527</td>\n",
              "      <td>24.79</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284804</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>1.919565</td>\n",
              "      <td>-0.301254</td>\n",
              "      <td>-3.249640</td>\n",
              "      <td>-0.557828</td>\n",
              "      <td>2.630515</td>\n",
              "      <td>3.031260</td>\n",
              "      <td>-0.296827</td>\n",
              "      <td>0.708417</td>\n",
              "      <td>0.432454</td>\n",
              "      <td>-0.484782</td>\n",
              "      <td>0.411614</td>\n",
              "      <td>0.063119</td>\n",
              "      <td>-0.183699</td>\n",
              "      <td>-0.510602</td>\n",
              "      <td>1.329284</td>\n",
              "      <td>0.140716</td>\n",
              "      <td>0.313502</td>\n",
              "      <td>0.395652</td>\n",
              "      <td>-0.577252</td>\n",
              "      <td>0.001396</td>\n",
              "      <td>0.232045</td>\n",
              "      <td>0.578229</td>\n",
              "      <td>-0.037501</td>\n",
              "      <td>0.640134</td>\n",
              "      <td>0.265745</td>\n",
              "      <td>-0.087371</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>-0.026561</td>\n",
              "      <td>67.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284805</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>-0.240440</td>\n",
              "      <td>0.530483</td>\n",
              "      <td>0.702510</td>\n",
              "      <td>0.689799</td>\n",
              "      <td>-0.377961</td>\n",
              "      <td>0.623708</td>\n",
              "      <td>-0.686180</td>\n",
              "      <td>0.679145</td>\n",
              "      <td>0.392087</td>\n",
              "      <td>-0.399126</td>\n",
              "      <td>-1.933849</td>\n",
              "      <td>-0.962886</td>\n",
              "      <td>-1.042082</td>\n",
              "      <td>0.449624</td>\n",
              "      <td>1.962563</td>\n",
              "      <td>-0.608577</td>\n",
              "      <td>0.509928</td>\n",
              "      <td>1.113981</td>\n",
              "      <td>2.897849</td>\n",
              "      <td>0.127434</td>\n",
              "      <td>0.265245</td>\n",
              "      <td>0.800049</td>\n",
              "      <td>-0.163298</td>\n",
              "      <td>0.123205</td>\n",
              "      <td>-0.569159</td>\n",
              "      <td>0.546668</td>\n",
              "      <td>0.108821</td>\n",
              "      <td>0.104533</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284806</th>\n",
              "      <td>172792.0</td>\n",
              "      <td>-0.533413</td>\n",
              "      <td>-0.189733</td>\n",
              "      <td>0.703337</td>\n",
              "      <td>-0.506271</td>\n",
              "      <td>-0.012546</td>\n",
              "      <td>-0.649617</td>\n",
              "      <td>1.577006</td>\n",
              "      <td>-0.414650</td>\n",
              "      <td>0.486180</td>\n",
              "      <td>-0.915427</td>\n",
              "      <td>-1.040458</td>\n",
              "      <td>-0.031513</td>\n",
              "      <td>-0.188093</td>\n",
              "      <td>-0.084316</td>\n",
              "      <td>0.041333</td>\n",
              "      <td>-0.302620</td>\n",
              "      <td>-0.660377</td>\n",
              "      <td>0.167430</td>\n",
              "      <td>-0.256117</td>\n",
              "      <td>0.382948</td>\n",
              "      <td>0.261057</td>\n",
              "      <td>0.643078</td>\n",
              "      <td>0.376777</td>\n",
              "      <td>0.008797</td>\n",
              "      <td>-0.473649</td>\n",
              "      <td>-0.818267</td>\n",
              "      <td>-0.002415</td>\n",
              "      <td>0.013649</td>\n",
              "      <td>217.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time         V1         V2  ...       V28  Amount  Class\n",
              "284802  172786.0 -11.881118  10.071785  ...  0.823731    0.77      0\n",
              "284803  172787.0  -0.732789  -0.055080  ... -0.053527   24.79      0\n",
              "284804  172788.0   1.919565  -0.301254  ... -0.026561   67.88      0\n",
              "284805  172788.0  -0.240440   0.530483  ...  0.104533   10.00      0\n",
              "284806  172792.0  -0.533413  -0.189733  ...  0.013649  217.00      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgZIjSv-uAYe",
        "colab_type": "text"
      },
      "source": [
        "## Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IQun6BguAYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shuffle and randomize data\n",
        "shuffled_data = credit_card_data.sample(frac=1)\n",
        "\n",
        "# Change Class column into Class_0 ([1 0] for legit data) and Class_1 ([0 1] for fraudulent data)\n",
        "one_hot_data = pd.get_dummies(shuffled_data, columns=['Class'])\n",
        "\n",
        "# Change all values into numbers between 0 and 1\n",
        "normalized_data = (one_hot_data - one_hot_data.min()) / (one_hot_data.max() - one_hot_data.min())\n",
        "\n",
        "# Store just columns V1 through V28 in df_X and columns Class_0 and Class_1 in df_y\n",
        "df_X = normalized_data.drop(['Class_0', 'Class_1'], axis=1)\n",
        "df_y = normalized_data[['Class_0', 'Class_1']]\n",
        "\n",
        "# Convert both data_frames into np arrays of float32\n",
        "ar_X, ar_y = np.asarray(df_X.values, dtype='float32'), np.asarray(df_y.values, dtype='float32')\n",
        "\n",
        "# Allocate first 80% of data into training data and remaining 20% into testing data\n",
        "train_size = int(0.8 * len(ar_X))\n",
        "(raw_X_train, raw_y_train) = (ar_X[:train_size], ar_y[:train_size])\n",
        "(raw_X_test, raw_y_test) = (ar_X[train_size:], ar_y[train_size:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCmT0hH_uAYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ada2d96b-7747-4331-b67f-8588a3f134cc"
      },
      "source": [
        "# Gets a percent of fraud vs legit transactions (0.0017% of transactions are fraudulent)\n",
        "count_legit, count_fraud = np.unique(credit_card_data['Class'], return_counts=True)[1]\n",
        "fraud_ratio = float(count_fraud / (count_legit + count_fraud))\n",
        "print('Percent of fraudulent transactions: ', fraud_ratio)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percent of fraudulent transactions:  0.001727485630620034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LlXsfKAuAYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Applies a logit weighting of 578 (1/0.0017) to fraudulent transactions to cause model to pay more attention to them\n",
        "weighting = 1 / fraud_ratio\n",
        "raw_y_train[:, 1] = raw_y_train[:, 1] * weighting"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-TrcJSluAYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_batches(data, labels, batch_size):\n",
        "    assert len(data) == len(labels)\n",
        "    \n",
        "    all_batches = list()\n",
        "    for i in range(0, len(data)):\n",
        "        all_batches.append((data[i], labels[i]))\n",
        "    random.shuffle(all_batches)\n",
        "        \n",
        "    batches = list()\n",
        "    while len(all_batches) >= batch_size:\n",
        "        \n",
        "        data_batch = list()\n",
        "        labels_batch = list()\n",
        "        for j in range(0, batch_size):\n",
        "            data, labels = all_batches.pop()\n",
        "            data_batch.append(data)\n",
        "            labels_batch.append(labels)\n",
        "            \n",
        "        batches.append((np.array(data_batch), np.array(labels_batch)))\n",
        "    \n",
        "    return batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVBbLSzmuAYq",
        "colab_type": "text"
      },
      "source": [
        "## Neural Networks Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT1UgLbmuAYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 30 cells for the input\n",
        "input_dimensions = ar_X.shape[1]\n",
        "\n",
        "# 2 cells for the output\n",
        "output_dimensions = ar_y.shape[1]\n",
        "\n",
        "# 100 cells for the 1st layer\n",
        "num_layer_1_cells = 100\n",
        "\n",
        "# 150 cells for the second layer\n",
        "num_layer_2_cells = 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQCdqRkBuAYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reset tensorflow graph\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# We will use these as inputs to the model when it comes time to train it (assign values at run time)\n",
        "X_train_node = tf.placeholder(tf.float32, [None, input_dimensions], name='X_train')\n",
        "y_train_node = tf.placeholder(tf.float32, [None, output_dimensions], name='y_train')\n",
        "# learning_rate_ = tf.placeholder(tf.float32, None, name=\"learning_rate\")\n",
        "\n",
        "# We will use these as inputs to the model once it comes time to test it\n",
        "X_test_node = tf.constant(raw_X_test, name='X_test')\n",
        "y_test_node = tf.constant(raw_y_test, name='y_test')\n",
        "\n",
        "# First layer takes in input and passes output to 2nd layer\n",
        "weight_1_node = tf.Variable(tf.zeros([input_dimensions, num_layer_1_cells]), name='weight_1')\n",
        "biases_1_node = tf.Variable(tf.zeros([num_layer_1_cells]), name='biases_1')\n",
        "\n",
        "# Second layer takes in input from 1st layer and passes output to 3rd layer\n",
        "weight_2_node = tf.Variable(tf.zeros([num_layer_1_cells, num_layer_2_cells]), name='weight_2')\n",
        "biases_2_node = tf.Variable(tf.zeros([num_layer_2_cells]), name='biases_2')\n",
        "\n",
        "# Third layer takes in input from 2nd layer and outputs [1 0] or [0 1] depending on fraud vs legit\n",
        "weight_3_node = tf.Variable(tf.zeros([num_layer_2_cells, output_dimensions]), name='weight_3')\n",
        "biases_3_node = tf.Variable(tf.zeros([output_dimensions]), name='biases_3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgmgQRw9uAYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to run an input tensor through the 3 layers and output a tensor that will give us a fraud/legit result\n",
        "# Each layer uses a different function to fit lines through the data and predict whether a given input tensor will \\\n",
        "#   result in a fraudulent or legitimate transaction\n",
        "\n",
        "def network(input_tensor):\n",
        "    \n",
        "    # Sigmoid fits modified data well\n",
        "    layer1 = tf.nn.sigmoid(tf.matmul(input_tensor, weight_1_node) + biases_1_node)\n",
        "    \n",
        "    # Dropout prevents model from becoming lazy and over confident\n",
        "    layer2 = tf.nn.dropout(tf.nn.sigmoid(tf.matmul(layer1, weight_2_node) + biases_2_node), 0.85)\n",
        "    \n",
        "    # Softmax works very well with one hot encoding which is how results are outputted\n",
        "    layer3 = tf.nn.softmax(tf.matmul(layer2, weight_3_node) + biases_3_node)\n",
        "    return layer3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgDE5gMCuAYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hyperparameters\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 5000\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XTU3zEHuAYz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "96d3d4d7-1616-4e47-ab66-3ec3d15f89c8"
      },
      "source": [
        "# Used to predict what results will be given training or testing input data\n",
        "# Remember, X_train_node is just a placeholder for now. We will enter values at run time\n",
        "y_train_prediction = network(X_train_node)\n",
        "y_test_prediction = network(X_test_node)\n",
        "\n",
        "# Cross entropy loss function measures differences between actual output and predicted output\n",
        "cross_entropy = tf.losses.softmax_cross_entropy(y_train_node, y_train_prediction)\n",
        "\n",
        "# Adam optimizer function will try to minimize loss (cross_entropy) but changing the 3 layers' variable values at a\n",
        "#   learning rate of 0.005\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
        "\n",
        "# Function to calculate the accuracy of the actual result vs the predicted result\n",
        "def calculate_accuracy(actual, predicted):\n",
        "    actual = np.argmax(actual, 1)\n",
        "    predicted = np.argmax(predicted, 1)\n",
        "    return (100 * np.sum(np.equal(predicted, actual)) / predicted.shape[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-9898d835bdd4>:8: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Gqd31gVuAY1",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHaiZp0wuAY2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e12d81fd-9172-46e9-aeb9-f2e7c25dc711"
      },
      "source": [
        "info = {'loss':[], 'val_loss':[], 'acc':[], 'val_acc':[]}\n",
        "\n",
        "with tf.Session() as session:\n",
        "    tf.global_variables_initializer().run()\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        batches = prepare_batches(raw_X_train, raw_y_train, batch_size)\n",
        "        \n",
        "        epoch_losses = []\n",
        "        epoch_accuracy = []\n",
        "        \n",
        "        while batches:\n",
        "\n",
        "            data_inputs, data_labels = batches.pop()\n",
        "        \n",
        "            _, batch_loss = session.run([optimizer, cross_entropy],\n",
        "                                             feed_dict={X_train_node: raw_X_train,\n",
        "                                                        y_train_node: raw_y_train})\n",
        "        \n",
        "            epoch_y_test, epoch_y_test_prediction = y_test_node.eval(),y_test_prediction.eval()\n",
        "            batch_acc = calculate_accuracy(epoch_y_test, epoch_y_test_prediction)\n",
        "\n",
        "            epoch_losses.append(batch_loss)\n",
        "            epoch_accuracy.append(batch_acc)\n",
        "\n",
        "\n",
        "        train_loss = np.mean(epoch_losses)\n",
        "        info['loss'].append(train_loss)\n",
        "\n",
        "        train_accuracy = np.mean(epoch_accuracy)\n",
        "        info['acc'].append(train_accuracy)\n",
        "        \n",
        "        val_loss = session.run(cross_entropy, feed_dict={X_train_node: raw_X_test, \n",
        "                                                              y_train_node: raw_y_test})\n",
        "        info['val_loss'].append(val_loss)\n",
        "\n",
        "        epoch_y_test, epoch_y_test_prediction = y_test_node.eval(), y_test_prediction.eval()\n",
        "        val_accuracy = calculate_accuracy(epoch_y_test, epoch_y_test_prediction)\n",
        "        info['val_acc'].append(val_accuracy)\n",
        "\n",
        "        print(\"Epoch: \" + str(epoch + 1) + \"/\" + str(epochs) + \":\\n\"\n",
        "              + \"      - Training loss: \" + str(train_loss) + \" (acc: \" + str(train_accuracy) + \")\\n\"\n",
        "              + \"      - Validation loss: \" + str(val_loss) + \" (acc: \" + str(val_accuracy) + \")\")\n",
        "    \n",
        "    final_y_test, final_y_test_prediction = y_test_node.eval(), y_test_prediction.eval()\n",
        "    final_val_accuracy = calculate_accuracy(final_y_test, final_y_test_prediction)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/20:\n",
            "      - Training loss: 1.36633 (acc: 99.71349320599698)\n",
            "      - Validation loss: 0.6656657 (acc: 99.29953302201467)\n",
            "Epoch: 2/20:\n",
            "      - Training loss: 1.3395617 (acc: 94.60478525644778)\n",
            "      - Validation loss: 0.6414866 (acc: 91.49081844036375)\n",
            "Epoch: 3/20:\n",
            "      - Training loss: 1.1791612 (acc: 95.65289140128506)\n",
            "      - Validation loss: 0.5095131 (acc: 98.24444366419718)\n",
            "Epoch: 4/20:\n",
            "      - Training loss: 1.0086645 (acc: 98.90585926680164)\n",
            "      - Validation loss: 0.43379763 (acc: 99.15382184614305)\n",
            "Epoch: 5/20:\n",
            "      - Training loss: 0.9230738 (acc: 99.41060121952647)\n",
            "      - Validation loss: 0.39563182 (acc: 99.42593307819249)\n",
            "Epoch: 6/20:\n",
            "      - Training loss: 0.8805494 (acc: 99.53430942265604)\n",
            "      - Validation loss: 0.37116212 (acc: 99.54004424001967)\n",
            "Epoch: 7/20:\n",
            "      - Training loss: 0.8546538 (acc: 99.5493291824179)\n",
            "      - Validation loss: 0.35778314 (acc: 99.59446648642955)\n",
            "Epoch: 8/20:\n",
            "      - Training loss: 0.83988416 (acc: 99.5492901700549)\n",
            "      - Validation loss: 0.36122885 (acc: 99.42593307819249)\n",
            "Epoch: 9/20:\n",
            "      - Training loss: 0.8275456 (acc: 99.52541460388797)\n",
            "      - Validation loss: 0.35261354 (acc: 99.47508865559496)\n",
            "Epoch: 10/20:\n",
            "      - Training loss: 0.8164743 (acc: 99.47270890145086)\n",
            "      - Validation loss: 0.35361338 (acc: 99.36799971911098)\n",
            "Epoch: 11/20:\n",
            "      - Training loss: 0.8081098 (acc: 99.43190196973423)\n",
            "      - Validation loss: 0.34820497 (acc: 99.3802886134616)\n",
            "Epoch: 12/20:\n",
            "      - Training loss: 0.79937285 (acc: 99.33273254294286)\n",
            "      - Validation loss: 0.3504532 (acc: 99.09939959973316)\n",
            "Epoch: 13/20:\n",
            "      - Training loss: 0.79426897 (acc: 99.26531917964805)\n",
            "      - Validation loss: 0.34672344 (acc: 99.09413293072575)\n",
            "Epoch: 14/20:\n",
            "      - Training loss: 0.7870519 (acc: 99.15967370059575)\n",
            "      - Validation loss: 0.34451434 (acc: 99.04497735332326)\n",
            "Epoch: 15/20:\n",
            "      - Training loss: 0.78059727 (acc: 99.02059462643712)\n",
            "      - Validation loss: 0.34264225 (acc: 99.08886626171834)\n",
            "Epoch: 16/20:\n",
            "      - Training loss: 0.7758344 (acc: 98.90449383409603)\n",
            "      - Validation loss: 0.34101722 (acc: 98.90804395913065)\n",
            "Epoch: 17/20:\n",
            "      - Training loss: 0.77213573 (acc: 98.84488294340477)\n",
            "      - Validation loss: 0.34263715 (acc: 98.82553281134791)\n",
            "Epoch: 18/20:\n",
            "      - Training loss: 0.7678744 (acc: 98.68668781136742)\n",
            "      - Validation loss: 0.34480774 (acc: 98.55693269197009)\n",
            "Epoch: 19/20:\n",
            "      - Training loss: 0.7668876 (acc: 98.59379937502194)\n",
            "      - Validation loss: 0.35224825 (acc: 97.93371019276009)\n",
            "Epoch: 20/20:\n",
            "      - Training loss: 0.7640134 (acc: 98.50961069562945)\n",
            "      - Validation loss: 0.3388212 (acc: 98.64471050876023)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkutWgekuAY3",
        "colab_type": "text"
      },
      "source": [
        "## Model Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yllWlyDTuAY4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d5e47ba-7e4d-4960-defc-99d057fe2c03"
      },
      "source": [
        "final_fraud_y_test = final_y_test[final_y_test[:, 1] == 1]\n",
        "final_fraud_y_test_prediction = final_y_test_prediction[final_y_test[:, 1] == 1]\n",
        "final_fraud_accuracy = calculate_accuracy(final_fraud_y_test, final_fraud_y_test_prediction)\n",
        "print('Final fraud specific accuracy: {0:.2f}%'.format(final_fraud_accuracy))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final fraud specific accuracy: 88.99%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm9IfYAhuAY6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "ffc78a3f-6606-4798-8238-e4aab2551594"
      },
      "source": [
        "fig1 = plt.figure()\n",
        "ax1 = fig1.add_subplot(111)\n",
        "ax1.plot(info['acc'], label='Training acc')\n",
        "ax1.plot(info['val_acc'], label='Validation acc')\n",
        "blue_patch = mpatches.Patch(color='#699cef', label='Training accuracy')\n",
        "orange_patch = mpatches.Patch(color='orange', label='Validation accuracy')\n",
        "ax1.legend(handles=[blue_patch, orange_patch])\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD5CAYAAADcDXXiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTq7SYTkuAY8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "de02aec3-4c98-4a17-9385-918f34461925"
      },
      "source": [
        "fig1 = plt.figure()\n",
        "ax2 = fig1.add_subplot(111)\n",
        "ax2.plot(info['loss'], label='Training loss')\n",
        "ax2.plot(info['val_loss'], label='Validation loss')\n",
        "blue_patch = mpatches.Patch(color='#699cef', label='Training loss')\n",
        "orange_patch = mpatches.Patch(color='orange', label='Validation loss')\n",
        "ax2.legend(handles=[blue_patch, orange_patch])\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD5CAYAAAA3Os7hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n35fUTwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGBE-XiZuAZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #metrics\n",
        "  y_p = tf.argmax(pred, 1)\n",
        "  val_accuracy, y_pred = sess.run([accuracy, y_p], feed_dict={x:test_arrays, y:test_label})\n",
        "\n",
        "  print \"validation accuracy:\", val_accuracy\n",
        "  y_true = np.argmax(test_label,1)\n",
        "  print \"Precision\", sk.metrics.precision_score(y_true, y_pred)\n",
        "  print \"Recall\", sk.metrics.recall_score(y_true, y_pred)\n",
        "  print \"f1_score\", sk.metrics.f1_score(y_true, y_pred)\n",
        "  print \"confusion_matrix\"\n",
        "  print sk.metrics.confusion_matrix(y_true, y_pred)\n",
        "  fpr, tpr, tresholds = sk.metrics.roc_curve(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNFk6FU0uAY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "session.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}